{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "hshaYVqPjh-z",
   "metadata": {
    "id": "hshaYVqPjh-z"
   },
   "source": [
    "# Information Theoretic Measures for Fairness-aware Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9255574f",
   "metadata": {},
   "source": [
    "In general, fairness and bias are considered relevant when decisions that impact people's lives, particularly with respect to a set of variables considered sensitive, such as gender, ethnicity, sexual orientation, disability, etc. In Machine Learning models, Outcomes might be skewed by a range of factors and thus might be considered unfair concerning specific groups or individuals.\n",
    "\n",
    "Features relevant for accurate decisions may lead to explicit or implicit forms of discrimination against unprivileged groups, such as those of a certain race or gender. This happens due to existing biases in the training data, which are often replicated by the learning algorithm.\n",
    "\n",
    "This model tries to tackle it by using information-theoretic measures which quantify the impact of different subsets of features on the accuracy and discrimination of the dependent variable(Outcome Variable). Then use the Shapley value function to quantify the marginal impact of each feature. This method focuses on the impact of features on discriminatory predictions and does not focus on a speciﬁc classiﬁer design."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TRT1P-q-jn1O",
   "metadata": {
    "id": "TRT1P-q-jn1O"
   },
   "source": [
    "## Loading the used packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "588edf2f",
   "metadata": {
    "id": "588edf2f"
   },
   "outputs": [],
   "source": [
    "#Load the required packages\n",
    "import pandas as pd \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "from sklearn.metrics import log_loss\n",
    "from scipy import optimize\n",
    "import copy\n",
    "import itertools\n",
    "import math\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "zSacw_lP2kJI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 658,
     "status": "ok",
     "timestamp": 1649552088514,
     "user": {
      "displayName": "Vaishak Vikas Naik",
      "userId": "08732323734527581313"
     },
     "user_tz": 240
    },
    "id": "zSacw_lP2kJI",
    "outputId": "59c646ab-1f61-4a51-ac9b-0bb552985333"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "P7lxO8KLFc0z",
   "metadata": {
    "id": "P7lxO8KLFc0z"
   },
   "source": [
    "# 1. Data Processing:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VyJFMOqhFqrx",
   "metadata": {
    "id": "VyJFMOqhFqrx"
   },
   "source": [
    "## Loading the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5xPpKy86DXlU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "executionInfo": {
     "elapsed": 260,
     "status": "ok",
     "timestamp": 1649552209080,
     "user": {
      "displayName": "Vaishak Vikas Naik",
      "userId": "08732323734527581313"
     },
     "user_tz": 240
    },
    "id": "5xPpKy86DXlU",
    "outputId": "3c18dd9a-4db2-40f9-a2ac-4ec00502db07"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>compas_screening_date</th>\n",
       "      <th>sex</th>\n",
       "      <th>dob</th>\n",
       "      <th>age</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>race</th>\n",
       "      <th>...</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>v_score_text</th>\n",
       "      <th>v_screening_date</th>\n",
       "      <th>in_custody</th>\n",
       "      <th>out_custody</th>\n",
       "      <th>priors_count.1</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>event</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>miguel hernandez</td>\n",
       "      <td>miguel</td>\n",
       "      <td>hernandez</td>\n",
       "      <td>2013-08-14</td>\n",
       "      <td>Male</td>\n",
       "      <td>1947-04-18</td>\n",
       "      <td>69</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-08-14</td>\n",
       "      <td>2014-07-07</td>\n",
       "      <td>2014-07-14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>327</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>kevon dixon</td>\n",
       "      <td>kevon</td>\n",
       "      <td>dixon</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>Male</td>\n",
       "      <td>1982-01-22</td>\n",
       "      <td>34</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>2013-01-26</td>\n",
       "      <td>2013-02-05</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>ed philo</td>\n",
       "      <td>ed</td>\n",
       "      <td>philo</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>Male</td>\n",
       "      <td>1991-05-14</td>\n",
       "      <td>24</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>marcu brown</td>\n",
       "      <td>marcu</td>\n",
       "      <td>brown</td>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>Male</td>\n",
       "      <td>1993-01-21</td>\n",
       "      <td>23</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>bouthy pierrelouis</td>\n",
       "      <td>bouthy</td>\n",
       "      <td>pierrelouis</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>Male</td>\n",
       "      <td>1973-01-22</td>\n",
       "      <td>43</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                name   first         last compas_screening_date   sex  \\\n",
       "0   1    miguel hernandez  miguel    hernandez            2013-08-14  Male   \n",
       "1   3         kevon dixon   kevon        dixon            2013-01-27  Male   \n",
       "2   4            ed philo      ed        philo            2013-04-14  Male   \n",
       "3   5         marcu brown   marcu        brown            2013-01-13  Male   \n",
       "4   6  bouthy pierrelouis  bouthy  pierrelouis            2013-03-26  Male   \n",
       "\n",
       "          dob  age          age_cat              race  ...  v_decile_score  \\\n",
       "0  1947-04-18   69  Greater than 45             Other  ...               1   \n",
       "1  1982-01-22   34          25 - 45  African-American  ...               1   \n",
       "2  1991-05-14   24     Less than 25  African-American  ...               3   \n",
       "3  1993-01-21   23     Less than 25  African-American  ...               6   \n",
       "4  1973-01-22   43          25 - 45             Other  ...               1   \n",
       "\n",
       "   v_score_text  v_screening_date  in_custody  out_custody  priors_count.1  \\\n",
       "0           Low        2013-08-14  2014-07-07   2014-07-14               0   \n",
       "1           Low        2013-01-27  2013-01-26   2013-02-05               0   \n",
       "2           Low        2013-04-14  2013-06-16   2013-06-16               4   \n",
       "3        Medium        2013-01-13         NaN          NaN               1   \n",
       "4           Low        2013-03-26         NaN          NaN               2   \n",
       "\n",
       "  start   end event two_year_recid  \n",
       "0     0   327     0              0  \n",
       "1     9   159     1              1  \n",
       "2     0    63     0              1  \n",
       "3     0  1174     0              0  \n",
       "4     0  1102     0              0  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data = pd.read_csv(\"compas-scores-two-years.csv\")\n",
    "data = pd.read_csv(\"../data/compas-scores-two-years.csv\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db04a228",
   "metadata": {
    "id": "db04a228"
   },
   "source": [
    "## Selecting the relevant features and pre processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "109954e4",
   "metadata": {
    "id": "109954e4"
   },
   "outputs": [],
   "source": [
    "def process_compas_dataset(df):     \n",
    "    df = df[[\"sex\",\"age\",\"age_cat\",\"race\",\"priors_count\",\"c_charge_degree\",\"c_jail_in\", \"c_jail_out\",'two_year_recid']]\n",
    "    df[\"two_year_recid\"] = df[\"two_year_recid\"].apply(lambda x: -1 if x==0 else 1)\n",
    "    \n",
    "    #Only select Caucasian/African American, encode to 0/1\n",
    "    df = df[df[\"race\"].isin([\"Caucasian\",\"African-American\"])]\n",
    "    \n",
    "    \n",
    "    #categorical encoding race, gender, charge_degree  \n",
    "    df[\"race\"] = df[\"race\"].apply(lambda x: 1 if x == \"Caucasian\" else 0)\n",
    "    df[\"gender_cat\"] = df[\"sex\"].apply(lambda x: 1 if x == \"Female\" else 0)\n",
    "    df = df.drop(columns = \"sex\")\n",
    "    df[\"charge_cat\"] = df[\"c_charge_degree\"].apply(lambda x: 1 if x == \"F\" else 0)\n",
    "    df = df.drop(columns = \"c_charge_degree\")\n",
    "    \n",
    "    \n",
    "    #Calculate length of stay\n",
    "    df[\"length_stay\"] = pd.to_datetime(df[\"c_jail_out\"]) - pd.to_datetime(df['c_jail_in'])\n",
    "    df[\"length_stay\"] = df[\"length_stay\"].apply(lambda x: x.days)\n",
    "    df = df.drop(columns = [\"c_jail_in\",\"c_jail_out\"])\n",
    "    df['length_stay'] = df[\"length_stay\"].apply(lambda x: 0 if x <= 7 else x)\n",
    "    df['length_stay'] = df[\"length_stay\"].apply(lambda x: 1 if 7< x <= 90 else x)\n",
    "    df['length_stay'] = df[\"length_stay\"].apply(lambda x: 2 if x > 90 else x)\n",
    "\n",
    "    \n",
    "    #Categorize priors count into 3 categories \n",
    "    df[\"priors_count\"] = df[\"priors_count\"].apply(lambda x: 0 if x==0 else x)\n",
    "    df[\"priors_count\"] = df[\"priors_count\"].apply(lambda x: 1 if (1<=x<=3) else x)\n",
    "    df[\"priors_count\"] = df[\"priors_count\"].apply(lambda x: 2 if x>3 else x)\n",
    "    \n",
    "    df['age_cat'].replace(['Greater than 45', '25 - 45', 'Less than 25'],\n",
    "                        [0, 1, 2], inplace=True)\n",
    "    df = df.drop(columns = [\"age\"])\n",
    "    \n",
    "    print(len(df.index))\n",
    "    df = df.dropna()\n",
    "    print(len(df.index))\n",
    "    \n",
    "    y_label = df[\"two_year_recid\"]\n",
    "    protected_attribute = df[\"race\"]\n",
    "    df = df.drop(columns=[\"two_year_recid\",\"race\"])\n",
    "    y_label, protected_attr, df = shuffle(y_label, protected_attribute, df, random_state = 42)\n",
    "\n",
    "    return y_label.to_numpy(), protected_attr.to_numpy(), df.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3684b8",
   "metadata": {
    "id": "9d3684b8"
   },
   "source": [
    "## Constructing our training and test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2o-vU7b2HmS2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 248,
     "status": "ok",
     "timestamp": 1649552214703,
     "user": {
      "displayName": "Vaishak Vikas Naik",
      "userId": "08732323734527581313"
     },
     "user_tz": 240
    },
    "id": "2o-vU7b2HmS2",
    "outputId": "4cd8ddc4-44eb-4bd3-d569-1be3eff08767"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6150\n",
      "5915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-195d6a5f3a17>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"two_year_recid\"] = df[\"two_year_recid\"].apply(lambda x: -1 if x==0 else 1)\n"
     ]
    }
   ],
   "source": [
    "#Still using compas dataset for evaluation \n",
    "y_label, protected_attr, X =  process_compas_dataset(data)\n",
    "\n",
    "train_index = int(len(X)*.80)\n",
    "x_train, y_train, race_train = X[:train_index], y_label[:train_index], protected_attr[:train_index]\n",
    "x_test, y_test, race_test = X[train_index:], y_label[train_index:],protected_attr[train_index:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ToMm-_50OmTm",
   "metadata": {
    "id": "ToMm-_50OmTm"
   },
   "source": [
    "# Implementation FFS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07030edf",
   "metadata": {
    "id": "07030edf"
   },
   "outputs": [],
   "source": [
    "\"\"\"This cell contains utility functions called in the proceeding cells.\"\"\"\n",
    "\n",
    "def get_uniq_vals_in_arr(arr):\n",
    "    \"\"\"Returns unique values in array.\n",
    "    \n",
    "    :param arr (np.array) n * m matrix\n",
    "    :return (list) uniq_vals[i] contains unique values of ith column in arr\n",
    "    \"\"\"\n",
    "    uniq_vals = []\n",
    "    for id_col in range(arr.shape[1]):\n",
    "        uniq_vals.append(np.unique(arr[:, id_col]).tolist())\n",
    "    return uniq_vals\n",
    "\n",
    "\n",
    "def powerset(seq):\n",
    "    \"\"\"\n",
    "    Returns all the subsets of this set. This is a generator.\n",
    "    \"\"\"\n",
    "    if len(seq) <= 1:\n",
    "        yield seq\n",
    "        yield []\n",
    "    else:\n",
    "        for item in powerset(seq[1:]):\n",
    "            yield [seq[0]]+item\n",
    "            yield item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5adef3d9",
   "metadata": {
    "id": "5adef3d9"
   },
   "outputs": [],
   "source": [
    "\"\"\"This cell contains code for all the routines needed to calculate the Shapley coefficients.\"\"\"\n",
    "\n",
    "def get_info_coef(left, right):\n",
    "    # Both arrays NEED same number of rows\n",
    "    assert left.shape[0] == right.shape[0]\n",
    "    num_rows = left.shape[0]\n",
    "    num_left_cols = left.shape[1]\n",
    "        \n",
    "    concat_mat = np.concatenate((left, right), axis=1)\n",
    "    concat_uniq_vals = get_uniq_vals_in_arr(concat_mat)\n",
    "    concat_combos = list(itertools.product(*concat_uniq_vals))\n",
    "    p_sum = 0\n",
    "    for vec in concat_combos:\n",
    "        p_r1_r2 = len(np.where((concat_mat == vec).all(axis=1))[0]) / num_rows\n",
    "        p_r1 = len(np.where((left == vec[:num_left_cols]).all(axis=1))[0]) / num_rows\n",
    "        p_r2 = len(np.where((right == vec[num_left_cols:]).all(axis=1))[0]) / num_rows\n",
    "        \n",
    "        if p_r1_r2 == 0 or p_r1 == 0 or p_r2 == 0:\n",
    "            p_iter = 0\n",
    "        else:\n",
    "            p_iter = p_r1_r2 * np.log(p_r1_r2 / p_r1) / p_r1\n",
    "        p_sum += np.abs(p_iter)\n",
    "    return p_sum\n",
    "\n",
    "\n",
    "def get_conditional_info_coef(left, right, conditional): \n",
    "    assert (left.shape[0] == right.shape[0]) and (left.shape[0] == conditional.shape[0])\n",
    "    num_rows = left.shape[0]\n",
    "    num_left_cols = left.shape[1]\n",
    "    num_right_cols = right.shape[1]\n",
    "\n",
    "    right_concat_mat = np.concatenate((right, conditional), axis=1)    \n",
    "    concat_mat = np.concatenate((left, right_concat_mat), axis=1)\n",
    "    concat_uniq_vals = get_uniq_vals_in_arr(concat_mat)\n",
    "    concat_combos = list(itertools.product(*concat_uniq_vals))\n",
    "    p_sum = 0\n",
    "    for vec in concat_combos:\n",
    "        p_r1_r2 = len(np.where((concat_mat == vec).all(axis=1))[0]) / num_rows\n",
    "        p_r1 = len(np.where((left == vec[:num_left_cols]).all(axis=1))[0]) / num_rows\n",
    "        p_r2 = len(np.where((concat_mat[:, num_left_cols: -num_right_cols] == vec[num_left_cols: -num_right_cols]).all(axis=1))[0]) / num_rows\n",
    "        \n",
    "        try:\n",
    "            p_r1_given_r3 = len(np.where((concat_mat[:, :num_left_cols] == vec[:num_left_cols]).all(axis=1) & (concat_mat[:, -num_right_cols:] == vec[-num_right_cols:]).all(axis=1))[0]) / len(np.where((concat_mat[:, -num_right_cols:] == vec[-num_right_cols:]).all(axis=1))[0])\n",
    "        except ZeroDivisionError:\n",
    "            p_r1_given_r3 = 0\n",
    "        \n",
    "        if p_r1_r2 == 0 or p_r1 == 0 or p_r2 == 0 or p_r1_given_r3 == 0:\n",
    "            p_iter = 0\n",
    "        else:\n",
    "            p_iter = p_r1_r2 * np.log(p_r1_r2 / p_r2) / p_r1_given_r3\n",
    "        p_sum += np.abs(p_iter)\n",
    "    return p_sum\n",
    "\n",
    "\n",
    "def get_acc_coef(y, x_s, x_s_c, protected_attr):\n",
    "    conditional = np.concatenate((x_s_c, protected_attr), axis=1)\n",
    "    return get_conditional_info_coef(y, x_s, conditional)\n",
    "\n",
    "\n",
    "def get_disc_coef(y, x_s, protected_attr):\n",
    "    x_s_a = np.concatenate((x_s, protected_attr), axis=1)\n",
    "    return get_info_coef(y, x_s_a) * get_info_coef(x_s, protected_attr) * get_conditional_info_coef(x_s, protected_attr, y)\n",
    "\n",
    "\n",
    "def get_shapley_acc_i(y, x, protected_attr, i):\n",
    "    \"\"\"Returns Shapley coeffecient of ith feature in x.\"\"\"\n",
    "    \n",
    "    num_features = x.shape[1]\n",
    "    lst_idx = list(range(num_features))\n",
    "    lst_idx.pop(i)\n",
    "    power_set = [x for x in powerset(lst_idx) if len(x) > 0]\n",
    "    \n",
    "    shapley = 0\n",
    "    for set_idx in power_set:\n",
    "        coef = math.factorial(len(set_idx)) * math.factorial(num_features - len(set_idx) - 1) / math.factorial(num_features)\n",
    "        \n",
    "        # Calculate v(T U {i})\n",
    "        idx_xs_incl = copy.copy(set_idx)\n",
    "        idx_xs_incl.append(i)\n",
    "        idx_xsc_incl = list(set(list(range(num_features))).difference(set(idx_xs_incl)))\n",
    "        acc_incl = get_acc_coef(y.reshape(-1, 1), x[:, idx_xs_incl], x[:, idx_xsc_incl], protected_attr.reshape(-1, 1))\n",
    "        \n",
    "        # Calculate v(T)\n",
    "        idx_xsc_excl = list(range(num_features))\n",
    "        idx_xsc_excl.pop(i)\n",
    "        idx_xsc_excl = list(set(idx_xsc_excl).difference(set(set_idx)))\n",
    "        acc_excl = get_acc_coef(y.reshape(-1, 1), x[:, set_idx], x[:, idx_xsc_excl], protected_attr.reshape(-1, 1))\n",
    "        \n",
    "        marginal = acc_incl - acc_excl\n",
    "        shapley = shapley + coef * marginal\n",
    "    return shapley\n",
    "\n",
    "\n",
    "def get_shapley_disc_i(y, x, protected_attr, i):\n",
    "    \"\"\"Returns Shapley coeffecient of ith feature in x.\"\"\"\n",
    "    \n",
    "    num_features = x.shape[1]\n",
    "    lst_idx = list(range(num_features))\n",
    "    lst_idx.pop(i)\n",
    "    power_set = [x for x in powerset(lst_idx) if len(x) > 0]\n",
    "    \n",
    "    shapley = 0\n",
    "    for set_idx in power_set:\n",
    "        coef = math.factorial(len(set_idx)) * math.factorial(num_features - len(set_idx) - 1) / math.factorial(num_features)\n",
    "        \n",
    "        # Calculate v_D(T U {i})\n",
    "        idx_xs_incl = copy.copy(set_idx)\n",
    "        idx_xs_incl.append(i)\n",
    "        disc_incl = get_disc_coef(y.reshape(-1, 1), x[:, idx_xs_incl], protected_attr.reshape(-1, 1))\n",
    "        \n",
    "        # Calculate v_D(T)\n",
    "        disc_excl = get_disc_coef(y.reshape(-1, 1), x[:, set_idx], protected_attr.reshape(-1, 1))\n",
    "        \n",
    "        marginal = disc_incl - disc_excl\n",
    "        shapley = shapley + coef * marginal\n",
    "    return shapley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dbc173c1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 221139,
     "status": "ok",
     "timestamp": 1649552443925,
     "user": {
      "displayName": "Vaishak Vikas Naik",
      "userId": "08732323734527581313"
     },
     "user_tz": 240
    },
    "id": "dbc173c1",
    "outputId": "31a4ce62-db2e-483a-af2e-8ba7b55b8d64"
   },
   "outputs": [],
   "source": [
    "# Calculate Shapley disc, acc coefs for each feature over training data\n",
    "shap_acc = []\n",
    "shap_disc = []\n",
    "for i in range(5):\n",
    "    acc_i = get_shapley_acc_i(y_train, x_train, race_train, i)\n",
    "    disc_i = get_shapley_disc_i(y_train, x_train, race_train, i)\n",
    "    \n",
    "    shap_acc.append(acc_i)\n",
    "    shap_disc.append(disc_i)\n",
    "\n",
    "# Build Shapley output\n",
    "feature_names = [\"Age Categorical\",\"Prior Count\", \"Gender\", \"Charge Degree\", \"Length of Stay\"]\n",
    "shapley_df = pd.DataFrame(list(zip(feature_names, shap_acc, shap_disc)),\n",
    "                          columns=[\"Feature\", \"Shapley Accuracy\", \"Shapley Discrimination\"])\n",
    "shapley_df = shapley_df.sort_values(by=[\"Shapley Discrimination\"], ascending=[False]).reset_index(0, True)\n",
    "#shapley_df.to_csv(\"../output/compas-data-shapley-table.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e71bdcd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 146,
     "status": "ok",
     "timestamp": 1649553864651,
     "user": {
      "displayName": "Vaishak Vikas Naik",
      "userId": "08732323734527581313"
     },
     "user_tz": 240
    },
    "id": "9e71bdcd",
    "outputId": "1d7cf51f-2b32-4002-994a-4bcfddb72571"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Feature  Shapley Accuracy  Shapley Discrimination\n",
      "0      Prior Count          1.26E+00                5.44E+04\n",
      "1  Age Categorical          1.23E+00                5.38E+04\n",
      "2   Length of Stay          1.09E+00                5.32E+04\n",
      "3    Charge Degree          1.07E+00                4.36E+04\n",
      "4           Gender          9.91E-01                4.29E+04\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.2E' % x)\n",
    "print(shapley_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd228f48",
   "metadata": {},
   "source": [
    "We can see that 'Prior Count' has the most significant impact on both discrimination and accuracy, therefore removing it may be difficult for a classifier. However, while a feature like 'Age Cat' is very discriminatory, removing it would not have a significant impact on the accuracy of our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ccd899f2",
   "metadata": {
    "id": "ccd899f2"
   },
   "outputs": [],
   "source": [
    "test_acc = []\n",
    "test_cal = []\n",
    "\n",
    "# Build model for overall data inclusive of all features\n",
    "svm = SVC(kernel=\"linear\").fit(x_train, y_train)\n",
    "idx_race_1, idx_race_0  = np.where(race_test == 1)[0], np.where(race_test == 0)[0]\n",
    "test_acc.append(svm.score(x_test, y_test))\n",
    "test_cal.append(svm.score(x_test[idx_race_1], y_test[idx_race_1]) - svm.score(x_test[idx_race_0], y_test[idx_race_0]))\n",
    "\n",
    "# Eliminate one feature at a time build model\n",
    "for id_feature in range(x_train.shape[1]):\n",
    "    idxs = list(range(x_train.shape[1]))\n",
    "    idxs.pop(id_feature)\n",
    "    x_train_mod = x_train[:, idxs]\n",
    "    x_test_mod = x_test[:, idxs]\n",
    "    \n",
    "    svm = SVC(kernel=\"linear\").fit(x_train_mod, y_train)\n",
    "    acc = svm.score(x_test_mod, y_test)\n",
    "    cal = svm.score(x_test_mod[idx_race_1], y_test[idx_race_1]) - svm.score(x_test_mod[idx_race_0], y_test[idx_race_0])\n",
    "    \n",
    "    test_acc.append(acc)\n",
    "    test_cal.append(cal)\n",
    "    \n",
    "\n",
    "index_names = [\"None\",  \"Age Categorical\", \"Prior Count\", \"Gender\", \"Charge Degree\", \"Length of Stay\"]\n",
    "test_acc = [x * 100 for x in test_acc]\n",
    "test_cal = [x * 100 for x in test_cal]\n",
    "results = pd.DataFrame(list(zip(index_names, test_acc, test_cal)),\n",
    "                          columns=[\"Eliminating Feature\", \"Accuracy (%)\", \"Calibration (%)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a0fc3b4e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "executionInfo": {
     "elapsed": 139,
     "status": "ok",
     "timestamp": 1649553853429,
     "user": {
      "displayName": "Vaishak Vikas Naik",
      "userId": "08732323734527581313"
     },
     "user_tz": 240
    },
    "id": "a0fc3b4e",
    "outputId": "fe4eacbd-2335-4990-8002-1dec0bff608f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Eliminating Feature  Accuracy (%)  Calibration (%)\n",
      "0                None         65.77             2.47\n",
      "1     Age Categorical         61.54             2.43\n",
      "2         Prior Count         59.76             5.48\n",
      "3              Gender         63.06            -1.57\n",
      "4       Charge Degree         66.02             1.69\n",
      "5      Length of Stay         65.85             2.33\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c54886",
   "metadata": {},
   "source": [
    "When we run the classification model, our results align with the paper, where there is a significant drop in the accuracy when we remove the 'Prior Count.' But with that, our calibration value also goes up. So we assume that imposing one type of fairness might not replicate in other fairness matrices. So when deciding what fairness constraint to impose, domain knowledge also plays an important role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b93ed61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ITFFS.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
