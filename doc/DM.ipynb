{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TZstatsADS/ads-spring-2022-prj4-group-9-1/blob/main/doc/DM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. Introduction of the Problem:"
      ],
      "metadata": {
        "id": "MIEU08drjbv0"
      },
      "id": "MIEU08drjbv0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DM model explained :"
      ],
      "metadata": {
        "id": "hshaYVqPjh-z"
      },
      "id": "hshaYVqPjh-z"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the used packages"
      ],
      "metadata": {
        "id": "TRT1P-q-jn1O"
      },
      "id": "TRT1P-q-jn1O"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a879f3cc",
      "metadata": {
        "id": "a879f3cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86985fd5-72ac-4956-c096-ecc6830d0dcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dccp\n",
            "  Downloading dccp-1.0.4.tar.gz (8.0 kB)\n",
            "Requirement already satisfied: cvxpy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from dccp) (1.0.31)\n",
            "Requirement already satisfied: osqp>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from cvxpy>=0.3.5->dccp) (0.6.2.post0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from cvxpy>=0.3.5->dccp) (1.4.1)\n",
            "Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.7/dist-packages (from cvxpy>=0.3.5->dccp) (2.0.10)\n",
            "Requirement already satisfied: scs>=1.1.3 in /usr/local/lib/python3.7/dist-packages (from cvxpy>=0.3.5->dccp) (3.2.0)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from cvxpy>=0.3.5->dccp) (1.21.5)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from cvxpy>=0.3.5->dccp) (0.70.12.2)\n",
            "Requirement already satisfied: qdldl in /usr/local/lib/python3.7/dist-packages (from osqp>=0.4.1->cvxpy>=0.3.5->dccp) (0.1.5.post0)\n",
            "Requirement already satisfied: dill>=0.3.4 in /usr/local/lib/python3.7/dist-packages (from multiprocess->cvxpy>=0.3.5->dccp) (0.3.4)\n",
            "Building wheels for collected packages: dccp\n",
            "  Building wheel for dccp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dccp: filename=dccp-1.0.4-py3-none-any.whl size=7386 sha256=f303e782fffafc01b83df7b1a575fb35e88aeb6a5bc1554e6e4e8d07f317c2d2\n",
            "  Stored in directory: /root/.cache/pip/wheels/44/a0/2b/8944fc49959e6ae8cc9584719c236016c214a04baf6516e24d\n",
            "Successfully built dccp\n",
            "Installing collected packages: dccp\n",
            "Successfully installed dccp-1.0.4\n"
          ]
        }
      ],
      "source": [
        "#Loading the desired packages\n",
        "!pip install dccp\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cvxpy as cp\n",
        "import dccp\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Data Processing:\n"
      ],
      "metadata": {
        "id": "P7lxO8KLFc0z"
      },
      "id": "P7lxO8KLFc0z"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the data:"
      ],
      "metadata": {
        "id": "VyJFMOqhFqrx"
      },
      "id": "VyJFMOqhFqrx"
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/data/compas-scores-two-years.csv\")\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        },
        "id": "5xPpKy86DXlU",
        "outputId": "4c83736f-6869-4b0c-addf-35bb8e1c6dd8"
      },
      "id": "5xPpKy86DXlU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id                 name      first         last  \\\n",
              "0         1     miguel hernandez     miguel    hernandez   \n",
              "1         3          kevon dixon      kevon        dixon   \n",
              "2         4             ed philo         ed        philo   \n",
              "3         5          marcu brown      marcu        brown   \n",
              "4         6   bouthy pierrelouis     bouthy  pierrelouis   \n",
              "...     ...                  ...        ...          ...   \n",
              "7209  10996        steven butler     steven       butler   \n",
              "7210  10997      malcolm simmons    malcolm      simmons   \n",
              "7211  10999      winston gregory    winston      gregory   \n",
              "7212  11000          farrah jean     farrah         jean   \n",
              "7213  11001  florencia sanmartin  florencia    sanmartin   \n",
              "\n",
              "     compas_screening_date     sex         dob  age          age_cat  \\\n",
              "0               2013-08-14    Male  1947-04-18   69  Greater than 45   \n",
              "1               2013-01-27    Male  1982-01-22   34          25 - 45   \n",
              "2               2013-04-14    Male  1991-05-14   24     Less than 25   \n",
              "3               2013-01-13    Male  1993-01-21   23     Less than 25   \n",
              "4               2013-03-26    Male  1973-01-22   43          25 - 45   \n",
              "...                    ...     ...         ...  ...              ...   \n",
              "7209            2013-11-23    Male  1992-07-17   23     Less than 25   \n",
              "7210            2014-02-01    Male  1993-03-25   23     Less than 25   \n",
              "7211            2014-01-14    Male  1958-10-01   57  Greater than 45   \n",
              "7212            2014-03-09  Female  1982-11-17   33          25 - 45   \n",
              "7213            2014-06-30  Female  1992-12-18   23     Less than 25   \n",
              "\n",
              "                  race  ...  v_decile_score  v_score_text  v_screening_date  \\\n",
              "0                Other  ...               1           Low        2013-08-14   \n",
              "1     African-American  ...               1           Low        2013-01-27   \n",
              "2     African-American  ...               3           Low        2013-04-14   \n",
              "3     African-American  ...               6        Medium        2013-01-13   \n",
              "4                Other  ...               1           Low        2013-03-26   \n",
              "...                ...  ...             ...           ...               ...   \n",
              "7209  African-American  ...               5        Medium        2013-11-23   \n",
              "7210  African-American  ...               5        Medium        2014-02-01   \n",
              "7211             Other  ...               1           Low        2014-01-14   \n",
              "7212  African-American  ...               2           Low        2014-03-09   \n",
              "7213          Hispanic  ...               4           Low        2014-06-30   \n",
              "\n",
              "      in_custody  out_custody  priors_count.1 start   end event two_year_recid  \n",
              "0     2014-07-07   2014-07-14               0     0   327     0              0  \n",
              "1     2013-01-26   2013-02-05               0     9   159     1              1  \n",
              "2     2013-06-16   2013-06-16               4     0    63     0              1  \n",
              "3            NaN          NaN               1     0  1174     0              0  \n",
              "4            NaN          NaN               2     0  1102     0              0  \n",
              "...          ...          ...             ...   ...   ...   ...            ...  \n",
              "7209  2013-11-22   2013-11-24               0     1   860     0              0  \n",
              "7210  2014-01-31   2014-02-02               0     1   790     0              0  \n",
              "7211  2014-01-13   2014-01-14               0     0   808     0              0  \n",
              "7212  2014-03-08   2014-03-09               3     0   754     0              0  \n",
              "7213  2015-03-15   2015-03-15               2     0   258     0              1  \n",
              "\n",
              "[7214 rows x 53 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c60817ff-5b5a-482e-9662-cad884c4756c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>name</th>\n",
              "      <th>first</th>\n",
              "      <th>last</th>\n",
              "      <th>compas_screening_date</th>\n",
              "      <th>sex</th>\n",
              "      <th>dob</th>\n",
              "      <th>age</th>\n",
              "      <th>age_cat</th>\n",
              "      <th>race</th>\n",
              "      <th>...</th>\n",
              "      <th>v_decile_score</th>\n",
              "      <th>v_score_text</th>\n",
              "      <th>v_screening_date</th>\n",
              "      <th>in_custody</th>\n",
              "      <th>out_custody</th>\n",
              "      <th>priors_count.1</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>event</th>\n",
              "      <th>two_year_recid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>miguel hernandez</td>\n",
              "      <td>miguel</td>\n",
              "      <td>hernandez</td>\n",
              "      <td>2013-08-14</td>\n",
              "      <td>Male</td>\n",
              "      <td>1947-04-18</td>\n",
              "      <td>69</td>\n",
              "      <td>Greater than 45</td>\n",
              "      <td>Other</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>Low</td>\n",
              "      <td>2013-08-14</td>\n",
              "      <td>2014-07-07</td>\n",
              "      <td>2014-07-14</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>327</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>kevon dixon</td>\n",
              "      <td>kevon</td>\n",
              "      <td>dixon</td>\n",
              "      <td>2013-01-27</td>\n",
              "      <td>Male</td>\n",
              "      <td>1982-01-22</td>\n",
              "      <td>34</td>\n",
              "      <td>25 - 45</td>\n",
              "      <td>African-American</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>Low</td>\n",
              "      <td>2013-01-27</td>\n",
              "      <td>2013-01-26</td>\n",
              "      <td>2013-02-05</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>159</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>ed philo</td>\n",
              "      <td>ed</td>\n",
              "      <td>philo</td>\n",
              "      <td>2013-04-14</td>\n",
              "      <td>Male</td>\n",
              "      <td>1991-05-14</td>\n",
              "      <td>24</td>\n",
              "      <td>Less than 25</td>\n",
              "      <td>African-American</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>Low</td>\n",
              "      <td>2013-04-14</td>\n",
              "      <td>2013-06-16</td>\n",
              "      <td>2013-06-16</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>marcu brown</td>\n",
              "      <td>marcu</td>\n",
              "      <td>brown</td>\n",
              "      <td>2013-01-13</td>\n",
              "      <td>Male</td>\n",
              "      <td>1993-01-21</td>\n",
              "      <td>23</td>\n",
              "      <td>Less than 25</td>\n",
              "      <td>African-American</td>\n",
              "      <td>...</td>\n",
              "      <td>6</td>\n",
              "      <td>Medium</td>\n",
              "      <td>2013-01-13</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1174</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>bouthy pierrelouis</td>\n",
              "      <td>bouthy</td>\n",
              "      <td>pierrelouis</td>\n",
              "      <td>2013-03-26</td>\n",
              "      <td>Male</td>\n",
              "      <td>1973-01-22</td>\n",
              "      <td>43</td>\n",
              "      <td>25 - 45</td>\n",
              "      <td>Other</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>Low</td>\n",
              "      <td>2013-03-26</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1102</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7209</th>\n",
              "      <td>10996</td>\n",
              "      <td>steven butler</td>\n",
              "      <td>steven</td>\n",
              "      <td>butler</td>\n",
              "      <td>2013-11-23</td>\n",
              "      <td>Male</td>\n",
              "      <td>1992-07-17</td>\n",
              "      <td>23</td>\n",
              "      <td>Less than 25</td>\n",
              "      <td>African-American</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>Medium</td>\n",
              "      <td>2013-11-23</td>\n",
              "      <td>2013-11-22</td>\n",
              "      <td>2013-11-24</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>860</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7210</th>\n",
              "      <td>10997</td>\n",
              "      <td>malcolm simmons</td>\n",
              "      <td>malcolm</td>\n",
              "      <td>simmons</td>\n",
              "      <td>2014-02-01</td>\n",
              "      <td>Male</td>\n",
              "      <td>1993-03-25</td>\n",
              "      <td>23</td>\n",
              "      <td>Less than 25</td>\n",
              "      <td>African-American</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>Medium</td>\n",
              "      <td>2014-02-01</td>\n",
              "      <td>2014-01-31</td>\n",
              "      <td>2014-02-02</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>790</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7211</th>\n",
              "      <td>10999</td>\n",
              "      <td>winston gregory</td>\n",
              "      <td>winston</td>\n",
              "      <td>gregory</td>\n",
              "      <td>2014-01-14</td>\n",
              "      <td>Male</td>\n",
              "      <td>1958-10-01</td>\n",
              "      <td>57</td>\n",
              "      <td>Greater than 45</td>\n",
              "      <td>Other</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>Low</td>\n",
              "      <td>2014-01-14</td>\n",
              "      <td>2014-01-13</td>\n",
              "      <td>2014-01-14</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>808</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7212</th>\n",
              "      <td>11000</td>\n",
              "      <td>farrah jean</td>\n",
              "      <td>farrah</td>\n",
              "      <td>jean</td>\n",
              "      <td>2014-03-09</td>\n",
              "      <td>Female</td>\n",
              "      <td>1982-11-17</td>\n",
              "      <td>33</td>\n",
              "      <td>25 - 45</td>\n",
              "      <td>African-American</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>Low</td>\n",
              "      <td>2014-03-09</td>\n",
              "      <td>2014-03-08</td>\n",
              "      <td>2014-03-09</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>754</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7213</th>\n",
              "      <td>11001</td>\n",
              "      <td>florencia sanmartin</td>\n",
              "      <td>florencia</td>\n",
              "      <td>sanmartin</td>\n",
              "      <td>2014-06-30</td>\n",
              "      <td>Female</td>\n",
              "      <td>1992-12-18</td>\n",
              "      <td>23</td>\n",
              "      <td>Less than 25</td>\n",
              "      <td>Hispanic</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>Low</td>\n",
              "      <td>2014-06-30</td>\n",
              "      <td>2015-03-15</td>\n",
              "      <td>2015-03-15</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>258</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7214 rows Ã— 53 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c60817ff-5b5a-482e-9662-cad884c4756c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c60817ff-5b5a-482e-9662-cad884c4756c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c60817ff-5b5a-482e-9662-cad884c4756c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Selecting the relevant features :"
      ],
      "metadata": {
        "id": "P2KA6VAJFvRZ"
      },
      "id": "P2KA6VAJFvRZ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Select only Caucasian and African-American as our sensitive feature\n",
        "data = data[data[\"race\"].isin([\"Caucasian\",\"African-American\"])]"
      ],
      "metadata": {
        "id": "H_etxmg2Fye-"
      },
      "id": "H_etxmg2Fye-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the features to predict the target y\n",
        "X = data[[\"sex\",\"age_cat\",\"priors_count.1\",\"race\"]]\n",
        "y = data[\"two_year_recid\"]\n",
        "\n",
        "# Encode the categorical_features\n",
        "for categorical_feature in [\"sex\",\"age_cat\",\"race\"]:\n",
        "  categorical_variable = pd.get_dummies(X[categorical_feature]).iloc[:,0]\n",
        "  X = pd.concat([X,categorical_variable],axis=1)\n",
        "  X = X.drop(categorical_feature,axis=1)\n",
        "  X = X.rename(columns={list(X)[-1]:categorical_feature})"
      ],
      "metadata": {
        "id": "2o-vU7b2HmS2"
      },
      "id": "2o-vU7b2HmS2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constructing our training and test set:"
      ],
      "metadata": {
        "id": "2kbXDqnTOaUF"
      },
      "id": "2kbXDqnTOaUF"
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct the training and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/7, random_state=42)"
      ],
      "metadata": {
        "id": "FM9xMNWRNev3"
      },
      "id": "FM9xMNWRNev3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Implementing the Fairness model :"
      ],
      "metadata": {
        "id": "ToMm-_50OmTm"
      },
      "id": "ToMm-_50OmTm"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining the logistic loss:"
      ],
      "metadata": {
        "id": "AAbCJuGoOvgF"
      },
      "id": "AAbCJuGoOvgF"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.extmath import weighted_mode\n",
        "\n",
        "def logistic_loss(X,y,weight):\n",
        "  '''\n",
        "      Compute the logistic loss using the data set [X,y]\n",
        "\n",
        "      Parameters\n",
        "      ----------\n",
        "      X : arrays\n",
        "        Training features\n",
        "      y : arrays \n",
        "        Training target\n",
        "      weight : array of size num_features\n",
        "        The weight of our logistic regression model\n",
        "  '''\n",
        "  return 1/len(X)*cp.sum(cp.logistic(X @ weight)-cp.multiply(y,X @ weight))"
      ],
      "metadata": {
        "id": "Z-PRi9pOOp2j"
      },
      "id": "Z-PRi9pOOp2j",
      "execution_count": 493,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing the DM model:"
      ],
      "metadata": {
        "id": "yh23wonFUDK0"
      },
      "id": "yh23wonFUDK0"
    },
    {
      "cell_type": "code",
      "source": [
        "class boundary_decision:\n",
        "  ''' \n",
        "      This class compute the boundary decision as\n",
        "      defined in the paper for different decision\n",
        "\n",
        "      ...\n",
        "\n",
        "      Parameters :\n",
        "      ------------\n",
        "\n",
        "      decision : str\n",
        "          name of the missclassification measure tackled\n",
        "          choice in (\"OMR\",\"FPR\",\"FNR\")\n",
        "  '''\n",
        "\n",
        "  def __init__(self, decision=\"OMR\"):\n",
        "    self.decision = decision\n",
        "\n",
        "  def __call__(self,X,y, weight):\n",
        "    '''\n",
        "    Return the boundary decision (g_theta in the paper) according to the \n",
        "    missclassification measure we want to tackled\n",
        "\n",
        "    Parameters :\n",
        "    ------------\n",
        "    X : arrays\n",
        "        Training features\n",
        "    y : arrays \n",
        "        Training target\n",
        "    weight : array of size num_features\n",
        "        The weight of our logistic regression model\n",
        "    '''\n",
        "    if self.decision == \"OMR\":\n",
        "      return cp.minimum(0, cp.multiply(y,(X @ weight)))\n",
        "    if self.decision == \"FPR\":\n",
        "      return cp.minimum(0, cp.multiply((1-y)*(2*y-1),(X @ weight)))\n",
        "    if self.decision == \"FNR\":\n",
        "      return cp.minimum(0, cp.multiply(y*(2*y-1),(X @ weight)))\n",
        "  \n",
        "  def convexified(self,X,y, weight, new_weight):\n",
        "    '''\n",
        "    Return the linearized boundary decision around an input weight according to the \n",
        "    missclassification measure we want to tackled\n",
        "\n",
        "    Parameters :\n",
        "    ------------\n",
        "    X : arrays\n",
        "        Training features\n",
        "    y : arrays \n",
        "        Training target\n",
        "    weight : array of size num_features\n",
        "        The weight around which the boundary decision is\n",
        "        linearized\n",
        "    new_weight : array of size num_features\n",
        "        The weight in which we want to evaluate the \n",
        "        convexified boundary decision\n",
        "    '''\n",
        "    if self.decision == \"OMR\":\n",
        "      dirac = y*(X @ weight)>=0\n",
        "      return self(X,y,weight)+cp.multiply(y*dirac,(X @ (new_weight-weight)))\n",
        "\n",
        "    if self.decision == \"FPR\":\n",
        "      dirac = (1-y)*(2*y-1)*(X @ weight)<=0\n",
        "      return self(X,y,weight)+cp.multiply(dirac*(1-y)*(2*y-1),X @ (new_weight-weight))\n",
        "      \n",
        "    if self.decision == \"FNR\":\n",
        "      dirac = y*(2*y-1)*(X @ weight) <=0\n",
        "      return self(X,y,weight)+ cp.multiply(dirac*y*(2*y-1),X @ (new_weight-weight))"
      ],
      "metadata": {
        "id": "Xnz2qRxvnDLd"
      },
      "id": "Xnz2qRxvnDLd",
      "execution_count": 494,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DM:\n",
        "    ''' \n",
        "        This class compute a default solver \n",
        "        to get train a classifier without disparate treatment.\n",
        "        Only logistic classifier was implemented yet but new implementation\n",
        "        can be seen by changing the loss.\n",
        "\n",
        "        ...\n",
        "\n",
        "        Parameters :\n",
        "        ------------\n",
        "\n",
        "        X : arrays\n",
        "            Training features\n",
        "        y : arrays \n",
        "            Training target\n",
        "        weight : array of size num_features\n",
        "            Initial weight of our logistic regression model\n",
        "        method : str\n",
        "            name of the missclassification measure tackled\n",
        "            choice in (\"OMR\",\"FPR\",\"FNR\")\n",
        "        \n",
        "        Hyperparameters :\n",
        "        ------------\n",
        "        c : float\n",
        "            Lower-upper bound of the constraint in the DM formulation\n",
        "        tau : float\n",
        "            Initial penalization constant of the slack variables in the CCP solver\n",
        "        mu : float\n",
        "            At each iteration of the solver, we increase tau by tau*mu\n",
        "    '''\n",
        "\n",
        "    def __init__(self, X, y, weight=np.zeros(4), c=0.1, tau=0.1, mu=1.1, method=\"OMR\"):\n",
        "      self.X = X\n",
        "      self.y = y\n",
        "      self.c = cp.Parameter(value=c)\n",
        "      self.weight = weight\n",
        "      self.si = cp.Variable(2,nonneg=True)\n",
        "      self.tau = tau\n",
        "      self.history = []\n",
        "      self.weight_k = cp.Variable(4, value = weight)\n",
        "      self.z = X[:,-1]\n",
        "      self.g = boundary_decision(method)\n",
        "\n",
        "    def solve_subproblem(self):\n",
        "      '''\n",
        "      This function is call by the CCP solver build from scratch.\n",
        "      Solve the subproblem as defined in the CCP solver.\n",
        "      '''\n",
        "      N = len(X[:,-1])\n",
        "      N1 = sum(X[:,-1])\n",
        "      N0 = N-N1\n",
        "      constraints = [\n",
        "               -N1/N*cp.sum(cp.multiply(self.z==0,self.g(self.X,self.y,self.weight_k)))+ N0/N*cp.sum(cp.multiply(self.z==1,self.g.convexified(self.X,self.y,self.weight,self.weight_k)))<=self.c+self.si[0],\n",
        "               -N0/N*cp.sum(cp.multiply(self.z==1,self.g(self.X,self.y,self.weight_k)))+ N1/N*cp.sum(cp.multiply(self.z==0,self.g.convexified(self.X,self.y,self.weight,self.weight_k)))<=self.c+self.si[1]\n",
        "               ]\n",
        "      loss = logistic_loss(self.X,self.y)(self.weight_k)\n",
        "      obj = cp.Minimize(loss+self.tau*cp.sum(self.si))\n",
        "      prob = cp.Problem(obj,constraints=constraints)\n",
        "      res = prob.solve(warm_start = True)\n",
        "      print(prob.status)\n",
        "      self.history.append(res)\n",
        "    \n",
        "    def predict(self,X_test):\n",
        "      '''\n",
        "      Compute the prediction of our logistic regression model using\n",
        "      the resulting weights.\n",
        "\n",
        "      Parameters :\n",
        "      -----------\n",
        "      X_test : array\n",
        "          New set of features on which we make our prediction\n",
        "      '''\n",
        "      prob = np.exp(X_test @ self.weight_k.value)/(1+np.exp(X_test @ self.weight_k.value))\n",
        "      return np.vectorize(lambda p: int(p>=0.5))(prob)\n",
        "    \n",
        "    def accuracy(self, X_val, y_val):\n",
        "      '''\n",
        "      Return the accuracy of our model by computing\n",
        "      the average number of TRP and FRP over the \n",
        "      data set [X_val, y_val]\n",
        "\n",
        "      Parameters : \n",
        "      -------------\n",
        "      X_val : array\n",
        "          Set of features on which we want to evaluate the accuracy\n",
        "          of our model\n",
        "      y_val : array\n",
        "          The target we are trying to reach when evaluating our model\n",
        "      '''\n",
        "      y_hat  = self.predict(X_val)\n",
        "      return np.sum(y_hat==y_val)/len(y_val)\n",
        "\n",
        "\n",
        "    def solve(self,T):\n",
        "      '''\n",
        "      CCP solver build from scratch based on the proposed algorithm\n",
        "\n",
        "      Parameters :\n",
        "      -------------\n",
        "      T : int\n",
        "          Number of iteration the solver is run.\n",
        "          Should we replace it by a termination criterion ?\n",
        "      '''\n",
        "      for i in range(T):\n",
        "        # We split the data into a training and validation set at each step\n",
        "        self.X, X_val, self.y, y_val = train_test_split(self.X,self.y,test_size=1/7)\n",
        "        self.z = X[:,-1]\n",
        "        self.solve_subproblem()\n",
        "        self.tau = np.minimum(self.tau*1.1,1)\n",
        "        self.weight = self.weight_k.value\n",
        "        print(\"epoch {} - accuracy {:.3f} - val_accuracy {:.3f}\".format(i,self.accuracy(self.X,self.y), self.accuracy(X_val,y_val)))\n",
        "        self.X = np.concatenate([self.X,X_val])\n",
        "        self.y = np.concatenate([self.y,y_val])\n",
        "      \n",
        "    def solve_DCCP(self):\n",
        "      '''\n",
        "      Solve the DM formulation using the DCCP package\n",
        "      '''\n",
        "      self.X, X_val, self.y, y_val = train_test_split(self.X,self.y,test_size=1/7)\n",
        "      self.z = X[:,-1]\n",
        "      N = len(X[:,-1])\n",
        "      N1 = sum(X[:,-1])\n",
        "      N0 = N-N1\n",
        "      constraints = [\n",
        "               -N1/N*cp.sum(cp.multiply(self.z==0,self.g(self.X,self.y,self.weight_k)))<=self.c - N0/N*cp.sum(cp.multiply(self.z==1,self.g(self.X,self.y,self.weight_k))),\n",
        "               -N0/N*cp.sum(cp.multiply(self.z==1,self.g(self.X,self.y,self.weight_k)))<=self.c - N1/N*cp.sum(cp.multiply(self.z==0,self.g(self.X,self.y,self.weight_k)))\n",
        "               ]\n",
        "      loss = logistic_loss(self.X,self.y)(self.weight_k)\n",
        "      obj = cp.Minimize(loss)\n",
        "      prob = cp.Problem(obj,constraints=constraints)\n",
        "      result = prob.solve(method='dccp', warm_start=True)\n",
        "      print(prob.status)\n",
        "      print(\"accuracy {:.3f} - val_accuracy {:.3f}\".format(self.accuracy(self.X,self.y), self.accuracy(X_val,y_val)))\n",
        "      self.X = np.concatenate([self.X,X_val])\n",
        "      self.y = np.concatenate([self.y,y_val])\n"
      ],
      "metadata": {
        "id": "BaIXk1Xe4WdN"
      },
      "id": "BaIXk1Xe4WdN",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "solver = DM(X_train.to_numpy(),y_train.to_numpy())"
      ],
      "metadata": {
        "id": "4mIr7agIPuQc"
      },
      "id": "4mIr7agIPuQc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "solver.solve(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCbmit8JCYEC",
        "outputId": "500d97ff-8913-4f0f-92f0-8df2b3ec8ecd"
      },
      "id": "aCbmit8JCYEC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "optimal\n",
            "epoch 0 - accuracy 0.500 - val_accuracy 0.517\n",
            "optimal\n",
            "epoch 1 - accuracy 0.566 - val_accuracy 0.578\n",
            "optimal\n",
            "epoch 2 - accuracy 0.576 - val_accuracy 0.562\n",
            "optimal\n",
            "epoch 3 - accuracy 0.606 - val_accuracy 0.572\n",
            "optimal\n",
            "epoch 4 - accuracy 0.592 - val_accuracy 0.614\n",
            "optimal\n",
            "epoch 5 - accuracy 0.598 - val_accuracy 0.591\n",
            "optimal\n",
            "epoch 6 - accuracy 0.597 - val_accuracy 0.590\n",
            "optimal\n",
            "epoch 7 - accuracy 0.595 - val_accuracy 0.604\n",
            "optimal\n",
            "epoch 8 - accuracy 0.598 - val_accuracy 0.576\n",
            "optimal\n",
            "epoch 9 - accuracy 0.599 - val_accuracy 0.588\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(solver.history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "UR5kpBgXGNvB",
        "outputId": "c5732322-a9cb-4034-c150-6e9ab77e39a4"
      },
      "id": "UR5kpBgXGNvB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fe58c934390>]"
            ]
          },
          "metadata": {},
          "execution_count": 443
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "solver.solve_DCCP()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrJFhTe0Xm9y",
        "outputId": "7ca0ea9d-501c-495b-b5b3-f74d20858f86"
      },
      "id": "xrJFhTe0Xm9y",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converged\n",
            "accuracy 0.595 - val_accuracy 0.587\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression(random_state=42).fit(X_train,y_train)\n",
        "model.score(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4w5gDpOqUe4p",
        "outputId": "685a2e4c-71c7-422f-8e87-92233930535e"
      },
      "id": "4w5gDpOqUe4p",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6313993174061433"
            ]
          },
          "metadata": {},
          "execution_count": 380
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "DM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}